{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQFvzAM0OvF5"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti103/blob/master/session-7/Oversampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnqURdKXOvF9"
   },
   "source": [
    "# Dealing with Imbalanced Data Set\n",
    "\n",
    "Welcome to the programming exercise. This is part of the series of exercises to help you acquire skills in different techniques to fine-tune your model.\n",
    "\n",
    "**You will learn:**\n",
    "- how to use oversampling correctly for imbalanced data set\n",
    "- how to perform oversampling using K-folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RwnjO0pOvF-"
   },
   "source": [
    "## Oversampling\n",
    "\n",
    "In this exercise, we will use a highly imbalanced data set from Lending Club that consists of data for both 'bad' and 'good' loans to illustrate the proper way of oversampling. The focus of this exercise is not to produce accurate model but to illustrate the 'effect' that wrong oversampling has on the model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLhPfND5OvF-"
   },
   "source": [
    "### 1. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "1155FtcFOvF_",
    "outputId": "73f5033a-d466-4420-89e2-d6dd4d495373"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='sklearn')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4uzbQmnOvGE"
   },
   "source": [
    "### 2. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OKm5pvtTOvGF"
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/nyp-sit/data/raw/master/lending-club-data.csv.zip'\n",
    "zip_file = \"lending_club-data.csv.zip\"\n",
    "\n",
    "# download the zip file and copy to a file 'lending-club-data.csv.zip'\n",
    "with urllib.request.urlopen(url) as response, open(zip_file, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "    \n",
    "# unzip the file to a folder 'data'\n",
    "data_file = 'lending_club_data.csv'\n",
    "\n",
    "with zipfile.ZipFile(zip_file,\"r\") as zip_ref:\n",
    "    zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUjfEldbOvGI"
   },
   "source": [
    "### 3. Some data exploratory analysis\n",
    "\n",
    "Here we are trying to find out some information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "_KUTDi-oOvGJ",
    "outputId": "0e9b7386-e409-4ecb-e479-040bcd3eb099"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1PMtr7wOvGP"
   },
   "source": [
    "Let us just find out about different features and their data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1283
    },
    "colab_type": "code",
    "id": "_KphBoylOvGQ",
    "outputId": "626ba1d6-0403-4a2d-b48c-f82b4eab4b70"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGorNXkCOvGU"
   },
   "source": [
    "In this exercise, we are trying to predict if a member will default on his loan or not. So we will be using the feature column 'bad_loans' as the label for our classification task. If the value of `bad_loan` is 1, it means it is a default (or bad loan), otherwise, it is 0.  \n",
    "\n",
    "***Exercise:***\n",
    "\n",
    "Find out how many samples in the data set is bad loans and how many are not. \n",
    "\n",
    "Hint: `value_counts()` in [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) give you the count of unique values\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "df.bad_loans.value_counts()\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "LxAwMqOLOvGV",
    "outputId": "f121e501-e098-4d29-db9f-7a72340a169b"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbTZ3HYROvGZ"
   },
   "source": [
    "Is the data set imbalanced? Clearly we have a lot of more good loans than bad loans (around 4 times more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-699YfGOvGZ"
   },
   "source": [
    "### 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqFZxW3POvGa"
   },
   "source": [
    "There are quite a lot of features in this data set but we are just going to use a few, just for demonstration purpose (as we are not really interested in actual performance of our model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiB1_iyKOvGb"
   },
   "outputs": [],
   "source": [
    "features = ['grade', 'home_ownership','emp_length_num', 'sub_grade','short_emp',\n",
    "            'dti', 'term', 'purpose', 'int_rate', 'last_delinq_none', 'last_major_derog_none',\n",
    "            'revol_util', 'total_rec_late_fee', 'payment_inc_ratio', 'bad_loans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThOEfOuTOvGe"
   },
   "source": [
    "***Exercise:*** \n",
    "\n",
    "Create a data frame that consist of the subset of features listed above.\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "df = df[features]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QcD4E6QMOvGf"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### \n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "3I0zJTN0OvGi",
    "outputId": "cc071b38-d5c9-440e-853a-de08080a2e0a"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54vsiwgBOvGm"
   },
   "source": [
    "Notice that `payment_inc_ratio` has some null values, and since it is only a small number, just remove the rows that have null values for `payment_inc_ratio`.\n",
    "\n",
    "***Exercise***\n",
    "\n",
    "Create a new data frame that have the rows that contains null values for `payment_inc_ratio` removed. \n",
    "\n",
    "Hint: `~df.payment_inc_ratio.isnull()` will give return a series of boolean(true/false mask) to indicate which rows of payment_inc_ration is **NOT** null. Construct the new data frame using `df[boolean mask]`\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "loans_df = df[~df.payment_inc_ratio.isnull()]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2LnIJIEOvGn"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "loans_df = None \n",
    "\n",
    "#### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "-kvTJH5-OvGq",
    "outputId": "d9301060-c894-4386-a3c3-d7908ff8c8d5"
   },
   "outputs": [],
   "source": [
    "loans_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdYkuMW2OvGs"
   },
   "source": [
    "***Exercise:*** \n",
    "\n",
    "Encode the categorical columns (dtype=object). You can use the convenience method `get_dummies()` provide by [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "loans_encoded = pd.get_dummies(loans_df)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtXWlMJuOvGt"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "loans_encoded = None\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1317
    },
    "colab_type": "code",
    "id": "Ee_Jj-lfOvGv",
    "outputId": "f434ba18-c5be-443e-a81d-f7c3de9cdac8"
   },
   "outputs": [],
   "source": [
    "loans_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pplOyf8XOvGz"
   },
   "source": [
    "### 5. Split the data set into train and test set\n",
    "\n",
    "***Exercise:*** \n",
    "\n",
    "Separate the features and the label.  \n",
    "\n",
    "Hint: use `df.drop()` and specify `axis=1` to remove a particular column in dataframe.\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "X_df = loans_encoded.drop(['bad_loans'], axis=1)\n",
    "y_df = loans_encoded['bad_loans']\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HV7UrEgrOvG0"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "# X_df contains all the feature columns and y_df contains only the label, i.e. bad_loans column\n",
    "\n",
    "X_df = None\n",
    "y_df = None \n",
    "\n",
    "\n",
    "### END CODE HERE ### \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, \n",
    "                                                    test_size = .1, \n",
    "                                                    stratify = y_df,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CeEr2-jBOvG4",
    "outputId": "48ecb29f-207c-4d15-fc4b-aa19b74dd211"
   },
   "outputs": [],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ms9xSxclOvG-"
   },
   "source": [
    "### 6. The ***wrong*** way to oversample ###\n",
    "\n",
    "With the training data created, we can oversample the minority class (the bad_loan = 1). In this exercise, we will use the SMOTE (from the [imblearn](https://imbalanced-learn.readthedocs.io/en/stable/index.html) library) to create synthetic samples of the minority class. \n",
    "\n",
    "After upsampling to a class ratio of 1.0 (i.e. 1 to 1 ratio between positive and negative classes) you should have a balanced dataset. In most cases, there’s often no need to balance the classes totally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09afPcnaOvG_"
   },
   "outputs": [],
   "source": [
    "# Set sampling_strategy='minority' to oversample only the minority class \n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=42)\n",
    "X_upsample, y_upsample = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYewJVUYOvHB"
   },
   "source": [
    "Now you see that the samples are totally balanced.  `np.bincount()` counts number of occurrences of each value in array of non-negative ints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AzcmiL-YOvHC",
    "outputId": "779deb33-eb62-4e85-c9a0-ec73bd9033be"
   },
   "outputs": [],
   "source": [
    "print(np.bincount(y_upsample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxd1sYiJOvHG"
   },
   "source": [
    "Now let us split the up-sampled training data set into training and validation set.\n",
    "\n",
    "***Note:***\n",
    "\n",
    "It might be a bit confusing as we talk about training sets. We have our original data set, `X` and we split into `X_train` and `X_test`.  We up-sample the `X_train` to get `X_upsample`. And then from the `X_upsample`, we further set aside a train set and validation set, which we call: `X_train_final`, and `X_val_final` to differentiate from the earlier `X_train` and `X_upsample`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8ewnQ5JOvHI"
   },
   "outputs": [],
   "source": [
    "#now split into cross validation\n",
    "\n",
    "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_upsample, y_upsample, \n",
    "                                                                          test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dyl14DBIOvHL"
   },
   "source": [
    "We then train a classifier and look at the performance of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "P5LXxQ5IOvHM",
    "outputId": "47e41a81-7a30-450e-9bd6-38eefd28ab29"
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=42)\n",
    "clf_rf.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANosUgZNOvHS"
   },
   "source": [
    "As we are interested in knowing how well our model is in picking out 'bad loan', it would be useful to look at the recall score of the model. \n",
    "\n",
    "***Exercise:*** \n",
    "\n",
    "Find the accuracy and the recall of the model on the validation set, i.e. `X_val_final`\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "y_val_final_pred = clf_rf.predict(X_val_final)\n",
    "\n",
    "accuracy = accuracy_score(y_val_final, y_val_final_pred)\n",
    "recall = recall_score(y_val_final, y_val_final_pred)\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "FYGhDwZDOvHS",
    "outputId": "98a31178-8ea0-4f95-c508-3276a79114c8"
   },
   "outputs": [],
   "source": [
    "### START THE CODE ### \n",
    "\n",
    "y_val_final_pred = None\n",
    "\n",
    "accuracy = None\n",
    "recall = None\n",
    "\n",
    "### END THE CODE ### \n",
    "\n",
    "print('accuracy = {}'.format(accuracy))\n",
    "print('recall = {}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IdknGvRgOvHV"
   },
   "source": [
    "You should expect to see around 80% recall, that is pretty good! It means the model correctly identified 80% of the total bad loans. But is this actually representative of how the model will perform? To find out, let's test the model on the test set we created initially.\n",
    "\n",
    "***Exercise:*** \n",
    "\n",
    "Find the accuracy and the recall of the model on the test set, i.e. `X_test`\n",
    "\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "y_val_final_pred = clf_rf.predict(X_val_final)\n",
    "\n",
    "accuracy = accuracy_score(y_val_final, y_val_final_pred)\n",
    "recall = recall_score(y_val_final, y_val_final_pred)\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "au3pbo7OOvHV",
    "outputId": "8fdc7e7c-0e13-4303-e3c6-688661db936d"
   },
   "outputs": [],
   "source": [
    "### START THE CODE ### \n",
    "y_test_pred = None\n",
    "\n",
    "accuracy = None\n",
    "recall = None \n",
    "\n",
    "\n",
    "### END THE CODE ### \n",
    "\n",
    "print('accuracy = {}'.format(accuracy))\n",
    "print('recall = {}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INAtz44QOvHa"
   },
   "source": [
    "Only 80% accuracy and 15% recall on the test data. That’s disappointing! What has happened?\n",
    "\n",
    "By oversampling before splitting into training and validation datasets, we “leaked” information from the validation set into the training of the model (refer to your lecture for more details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-fkAmtpOvHb"
   },
   "source": [
    "### 7. The ***right way*** to oversample\n",
    "\n",
    "So, let do it the right way and see what happens. This time round, we will oversample the training set and not the train + validation set. Oversampling is done after we set aside the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcdqazCuOvHc"
   },
   "outputs": [],
   "source": [
    "## Here we set aside a cross validation set first \n",
    "\n",
    "X_train_proper,  X_val_proper, y_train_proper, y_val_proper = train_test_split(X_train, y_train, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da-q1LuFOvHe"
   },
   "source": [
    "Now as before, we use SMOTE to oversample the minority class, but this time we only oversample from the train set.  \n",
    "\n",
    "***Note:***\n",
    "\n",
    "It might be a bit confusing as we talk about training sets. We have our original data set, `X` and we split into `X_train` and `X_test`.  And then from the `X_train`, we further set aside a train set and validation set, which we call: `X_train_proper`, and `X_val_proper` to differentiate from the earlier `X_train`. \n",
    "\n",
    "***Exercise:***\n",
    "\n",
    "Use SMOTE (as before) to over-sample the `X_train_proper`. \n",
    "\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=42) \n",
    "X_train_proper_upsampled, y_train_proper_upsampled = sm.fit_sample(X_train_proper, y_train_proper)\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KM6n8hrKOvHf"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "sm = None\n",
    "X_train_proper_upsampled, y_train_proper_upsampled = None \n",
    "\n",
    "\n",
    "### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spryBAWSOvHh"
   },
   "source": [
    "We then train a classifier and look at the performance of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "XixuEHXpOvHi",
    "outputId": "d8aa3c1c-49af-4e70-f2a2-b5e6f1afe685"
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=42)\n",
    "clf_rf.fit(X_train_proper_upsampled, y_train_proper_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WD-dU3A1OvHl"
   },
   "source": [
    "***Exercise:*** \n",
    "\n",
    "As before, find the accuracy and recall of the model on the validation set, i.e. `X_val_proper`\n",
    "\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "y_val_proper_pred = clf_rf.predict(X_val_proper)\n",
    "\n",
    "accuracy = accuracy_score(y_val_proper, y_val_proper_pred )\n",
    "recall = recall_score(y_val_proper, y_val_proper_pred )\n",
    "\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jqk5CSB3OvHl",
    "outputId": "33ffea09-2634-4dfd-d70f-7c7ce433e4eb"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "y_val_proper_pred = None\n",
    "\n",
    "accuracy = None\n",
    "recall = None\n",
    "\n",
    "\n",
    "### END THE CODE ### \n",
    "\n",
    "print('accuracy = {}'.format(accuracy))\n",
    "print('recall = {}'.format(recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mcgujKPMOvHp"
   },
   "source": [
    "This time round, we got only 17% recall. Let's see if this recall rate is more representative of the result on the test set. \n",
    "\n",
    "***Exercise:*** \n",
    "\n",
    "Find the accuracy and the recall of the model on the test set, i.e. `X_test`\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "y_test_pred = clf_rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "D5zbMK5KOvHq",
    "outputId": "61a5a30c-e638-4a6e-c450-27fd0a8d69d6"
   },
   "outputs": [],
   "source": [
    "### START THE CODE ### \n",
    "y_test_pred = None\n",
    "\n",
    "accuracy = None\n",
    "recall = None\n",
    "\n",
    "\n",
    "\n",
    "### END THE CODE ### \n",
    "\n",
    "print('accuracy = {}'.format(accuracy))\n",
    "print('recall = {}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qYkuhnyIOvHu"
   },
   "source": [
    "Now, we can see that the recall rate obtained from the validation set matches more closely the result from the test set, which is about 18% recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZG0w03bOvHw"
   },
   "source": [
    "### 8. Oversampling when doing K-Fold \n",
    "\n",
    "If you are doing K-fold cross validation, below is the code to show you how to do the oversampling properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "hFwOe5hgOvHw",
    "outputId": "c729bf5d-9ac8-457c-d0e6-84200d848588"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=42)\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=42) \n",
    "\n",
    "# We use enumerate() to return also the index position of the list so that we can print out the fold number\n",
    "for fold, (train_index, val_index) in enumerate(skfolds.split(X_train, y_train)):\n",
    "    #print(train_index, val_index)\n",
    "    X_train_fold = X_train.iloc[train_index]\n",
    "    y_train_fold = y_train.iloc[train_index]\n",
    "    X_val_fold = X_train.iloc[val_index]\n",
    "    y_val_fold = y_train.iloc[val_index]\n",
    "    X_train_fold_oversample, y_train_fold_oversample = sm.fit_sample(X_train_fold, y_train_fold)\n",
    "    clf_rf.fit(X_train_fold_oversample, y_train_fold_oversample)\n",
    "    y_val_fold_pred = clf_rf.predict(X_val_fold)\n",
    "    print('Accuracy score for {} fold: {}'.format(fold, accuracy_score(y_val_fold,y_val_fold_pred)))\n",
    "    print('Recall score for {} fold: {}'.format(fold, recall_score(y_val_fold, y_val_fold_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njcQmRKOP06j"
   },
   "source": [
    "If you don't want to use data frame for the StratifiedKFold, and prefer to work with numpy array\n",
    "\n",
    "You can first convert the X_train and y_train to numpy array as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "QZblkTYROvHz",
    "outputId": "1240c29c-8d6a-4b46-cb5a-bfe6a70e90c4"
   },
   "outputs": [],
   "source": [
    "X_train_arr = X_train.values\n",
    "y_train_arr = y_train.values\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=42)\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=42) \n",
    "\n",
    "# We use enumerate() to return also the index position of the list so that we can print out the fold number\n",
    "for fold, (train_index, val_index) in enumerate(skfolds.split(X_train_arr, y_train_arr)):\n",
    "    #print(train_index, val_index)\n",
    "    X_train_fold = X_train_arr[train_index]\n",
    "    y_train_fold = y_train_arr[train_index]\n",
    "    X_val_fold = X_train_arr[val_index]\n",
    "    y_val_fold = y_train_arr[val_index]\n",
    "    X_train_fold_oversample, y_train_fold_oversample = sm.fit_sample(X_train_fold, y_train_fold)\n",
    "    clf_rf.fit(X_train_fold_oversample, y_train_fold_oversample)\n",
    "    y_val_fold_pred = clf_rf.predict(X_val_fold)\n",
    "    print('Accuracy score for {} fold: {}'.format(fold, accuracy_score(y_val_fold,y_val_fold_pred)))\n",
    "    print('Recall score for {} fold: {}'.format(fold, recall_score(y_val_fold, y_val_fold_pred)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Oversampling(Solution).ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.8 (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
